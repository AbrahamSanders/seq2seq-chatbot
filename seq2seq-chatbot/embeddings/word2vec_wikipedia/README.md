# Word2Vec trained on English Wikipedia (Mikolov et al, 2013)

"Text embedding based on skipgram version of word2vec with 1 out-of-vocabulary bucket. Maps from text to 250-dimensional embedding vectors."

Shape: [,250]

Source*: [https://www.tensorflow.org/hub/modules/google/Wiki-words-250/1](https://www.tensorflow.org/hub/modules/google/Wiki-words-250/1)

Paper: [https://arxiv.org/abs/1301.3781](https://arxiv.org/abs/1301.3781)

Download: [here](https://drive.google.com/uc?id=1pV3LglHWn5wAmoCmt7u94hVHq8hLHXmj&export=download)

After download, unzip all files in the archive into this directory.

\* Note: The checkpoint file available for download was extracted from the TF Hub module at this location.